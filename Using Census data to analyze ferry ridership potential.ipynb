{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8abd5259-e629-4749-874d-26c5ad5b8f3d",
   "metadata": {},
   "source": [
    "# Using Census LODES data to analyze ferry ridership potential\n",
    "\n",
    "**Goal Output:** Determine the total amount of within-NYC commuters for whom the ferry is the fastest transit option.\n",
    "\n",
    "Our strategy is to build a model of hypothetical commutes within NYC. LODES data, provided by the census, tells us the total number of commutes occurring between each unique pair of census block groups -- a relatively small census geographies. PLUTO is a complete census of every building in NYC, maintained by the Dept. of City Planning. \n",
    "\n",
    "First, we will identify all buildings that are near both the subway and the ferry, such that it may be feasible to commute to/from these buildings via transit. We will record the census tracts where these buildings are -- these are the census tracts where a ferry or train commute is feasible. Next, we will remove from the LODES data any origin-destination pair that includes a census tract that is not near a ferry or subway stop. Then, for each remaining origin-destination pair in the LODES data, we will randomly, but representatively, select 50 hypothetical \"home\" locations and 50 hypothetical \"work\" locations from the PLUTO data. The more residential units the home building has, and the larger the work building is, the more likely it is to be chosen.\n",
    "\n",
    "For each hypothetical, quasi-random home-work pair we select, we will then calculate the transit time by a) ferry, b) subway, and c) a multimodal route involving both ferry and subway. Then, we will compare the pure subway commute to the ferry commutes. Recall that the LODES data tells us how many commuters there are for each unique home-work pair. For each home-work pair in our data, we will determine the fraction of hypothetical commutes where the ferry is the fastest option. We multiply this fraction by the actual number of commutes for the same home-work pair. Then, we add up this gross number for every home-work pair to get the *total number of commuters where the ferry is faster than the subway.* \n",
    "\n",
    "For example: If there are 80 commutes between census tract 1 in Brooklyn and census tract 1 in Manhattan, and 50% of these are found to be faster on the subway, then our gross number of ferry commutes is *40 commutes.* Do this multiplication for every home-work commute combination, then add up each resulting product.\n",
    "\n",
    "Since we are semi-randomly selecting home-work pairs (and not choosing *real* address-to-address commutes) we need to run multiple trials of this. If we run this task 50 times, selecting different random home-work pairs every time, then we should get an approximately normal distribution of output values. The mean value is about how many ferry commuters there are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fb1da7-ffc6-4307-b3a9-60b19cdcf898",
   "metadata": {},
   "source": [
    "## 1: Load in LODES Data:\n",
    "\n",
    "**Structure:** Each row is a unique combination of origin (home) census tracts and destination (work) census tracts. Columns represent the amount of commuters making that unique origin-destination commute.\n",
    "- LODES data originally comes in census block groups; I aggregated up to tracts to more easily merge other data sources.\n",
    "- I filtered the NY state-wide LODES dataset to include only origin-destination pairs that are within NYC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ea47eb-e4a4-41c8-8d07-10160de008fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "lodes_data = pd.read_csv(##REDACTED##)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2a803f-2768-4d09-86ee-d6af52814658",
   "metadata": {},
   "source": [
    "## 2: Locate residential and nonresidential addresses near both a ferry landing and subway station\n",
    "- For now, we are considering one type of commuter: people who can reasonable commute via ferry or via subway. There are *some* commuters for whom the ferry is always faster (for example, they may live directly on the waterfront in Bay Ridge or Rockaway), and we will address those types of commuters later. There are also some commuters who live far inland (like me, in Bushwick) where the ferry makes little sense at all.\n",
    "- The PLUTO dataset, maintained by the Dept of City Planning, includes data about all NYC addresses - both residential and nonresidential\n",
    "- For our purposes, the most important data within the PLUTO dataset is a building's census tract, its coordinates, its use type, its size, and the number of residential units. This tells us approximately how many people live in the building (recall that NYC has a very low vacancy rate) and, for non-residential addresses, the size is our best proxy for how many people work there.\n",
    "- Our goal is to create a dataset of all addresses that are reasonably close to both the subway and ferry, such that both modes are a potentially viable commuting option. We assume that people are willing to walk farther (1.0 mi) to a ferry than to a subway (0.5 mi) since ferry landings are just farther away in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b132d5-2507-4028-8437-02b03b24daa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Load in data on subway stops and ferry landings\n",
    "\n",
    "subway_stops = pd.read_excel(##REDACTED##)\n",
    "subway_stops['stop_name_line'] = subway_stops['stop_name'] + '/' + subway_stops['Line'].astype(str)\n",
    "ferry_stops = pd.read_csv(##REDACTED##)\n",
    "\n",
    "## rename columns \n",
    "ferry_stops=ferry_stops.rename(columns={'stop_lon':'ferry_lon', 'stop_lat':'ferry_lat'})\n",
    "subway_stops=subway_stops.rename(columns={'stop_lon':'subway_lon', 'stop_lat':'subway_lat'})\n",
    "\n",
    "## Load in PLUTO dataset, and create separate residential datasets and non-residential datasets\n",
    "pluto = pd.read_csv(##REDACTED##)\n",
    "pluto_residential = pluto[pluto['unitsres']!=0]\n",
    "\n",
    "## Non-residential addresses have  0 values for their number of residential units\n",
    "pluto_non_res = pluto[pluto['unitsres']==0]\n",
    "\n",
    "## Only keep the columns we need\n",
    "key_columns = [['borough', 'block', 'lot', 'ct2010', 'cb2010',\n",
    "                            'unitsres', 'latitude', 'longitude', 'address',\n",
    "                           'bct2020']]\n",
    "\n",
    "pluto_residential_data=pluto_residential[key_columns]\n",
    "\n",
    "# Convert PLUTO and subway/ferry stop dataframes to GeoDataFrames based on the longitude and latitude\n",
    "\n",
    "##### Create geography columns:\n",
    "pluto_residential_data['res_geometry'] = pluto_residential_data.apply(lambda row: Point(row['longitude'], row['latitude']), axis=1)\n",
    "pluto_non_res['nonres_geometry'] = pluto_non_res.apply(lambda row: Point(row['longitude'], row['latitude']), axis=1)\n",
    "ferry_stops['geometry'] = ferry_stops.apply(lambda row: Point(row['ferry_lon'], row['ferry_lat']), axis=1)\n",
    "subway_stops['geometry'] = subway_stops.apply(lambda row: Point(row['subway_lon'], row['subway_lat']), axis=1)\n",
    "\n",
    "##### Create Geodataframes\n",
    "gdf_residential = gpd.GeoDataFrame(pluto_residential_data, geometry='res_geometry', crs=\"EPSG:4326\").to_crs(crs=\"EPSG:3857\")\n",
    "gdf_work = gpd.GeoDataFrame(pluto_non_res, geometry='nonres_geometry', crs=\"EPSG:4326\").to_crs(crs=\"EPSG:3857\")\n",
    "gdf_subway = gpd.GeoDataFrame(subway_stops, geometry='geometry', crs=\"EPSG:4326\").to_crs(crs=\"EPSG:3857\")\n",
    "gdf_ferry = gpd.GeoDataFrame(ferry_stops, geometry='geometry', crs=\"EPSG:4326\").to_crs(crs=\"EPSG:3857\")\n",
    "\n",
    "# Set a buffer distance of 1 mile (in meters, 1 mile â‰ˆ 1609 meters) for the ferry and 0.5 miles for the subway\n",
    "subway_buffer_distance = 1609*0.5\n",
    "ferry_buffer_distance = 1609*1.0\n",
    "\n",
    "# Create buffers around subway stops and ferry landings\n",
    "\n",
    "def create_buffers(gdf, buffer_distance):\n",
    "    copy = gdf.copy()\n",
    "    return copy.buffer(buffer_distance)\n",
    "\n",
    "gdf_subway_buffer = create_buffers(gdf_subway, subway_buffer_distance)\n",
    "gdf_ferry_buffer = create_buffer(gdf_ferry_buffer, ferry_buffer_distance)\n",
    "\n",
    "def spatial_joins(gdf):\n",
    "    \n",
    "    joined_with_subway = gpd.sjoin(gdf, gdf_subway_buffer, how='inner', \n",
    "                                   predicate='intersects').drop(['index_right'], axis=1)\n",
    "    joined_with_ferry =  gpd.sjoin(joined_with_subway, gdf_ferry_buffer, how='inner', \n",
    "                                   predicate='intersects').drop(['index_right'], axis=1)\n",
    "    joined_with_ferry['ferry_geometry'] = joined_with_ferry.apply(lambda row: Point(row['ferry_lon'], \n",
    "                                                                                    row['ferry_lat']), \n",
    "                                                                  axis=1).set_crs(epsg=4326).to_crs(epsg=3857)\n",
    "    joined_with_ferry['subway_geometry'] = joined_with_ferry.apply(lambda row: Point(row['subway_lon'], \n",
    "                                                                                     row['subway_lat']), \n",
    "                                                                   axis=1).set_crs(epsg=4326).to_crs(epsg=3857)\n",
    "    \n",
    "    return joined_with_ferry.drop_duplicates(subset=['address', 'stop_name_left'])\n",
    "    \n",
    "gdf_residential = spatial_joins(gdf_residential)\n",
    "gdf_work = spatial_joins(gdf_work)\n",
    "                                                           \n",
    "## Edit the strings representing census tracts in the LODES data so we can more easily merge later on\n",
    "\n",
    "lodes_data['CT Number Home'] = lodes_data['trctname_home'].str.extract(r'(\\d+\\.?\\d*)').astype(float)*100\n",
    "lodes_data['CT Number Work'] = lodes_data['trctname_work'].str.extract(r'(\\d+\\.?\\d*)').astype(float)*100\n",
    "\n",
    "lodes_data['CT Number Home']=lodes_data['CT Number Home'].astype(int).astype(str)\n",
    "lodes_data['CT Number Work']=lodes_data['CT Number Work'].astype(int).astype(str)\n",
    "\n",
    "lodes_data['County Home'] = lodes_data['trctname_home'].str.extract(r'\\s*\\((.*?)\\)\\s*')\n",
    "lodes_data['County Work'] = lodes_data['trctname_work'].str.extract(r'\\s*\\((.*?)\\)\\s*')\n",
    "\n",
    "lodes_data['trctname_home'] = lodes_data['CT Number Home']+ \" \" + \"(\" + lodes_data['County Home'] + \")\"\n",
    "lodes_data['trctname_work'] = lodes_data['CT Number Work']+ \" \" + \"(\" + lodes_data['County Work'] + \")\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb3f436-76be-411e-9c96-10a42ada32af",
   "metadata": {},
   "source": [
    "## 3. Standardize census tract nomenclature, remove duplicates, and determine each address's actual distance to subways and ferries\n",
    "\n",
    "Basic data cleaning necessary to merge our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88054dcb-0518-4e4e-812c-b27c9ad08bb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Map boorugh to county so we can create a county column\n",
    "boro_to_county = {'MN': 'New York, NY',\n",
    "                  'QN': 'Queens, NY',\n",
    "                  'BX': 'Bronx, NY',\n",
    "                  'SI': 'Richmond, NY',\n",
    "                  'BK': 'Kings, NY'}\n",
    "\n",
    "gdf_residential['County']=gdf_residential['borough'].map(boro_to_county)\n",
    "gdf_work['County']=gdf_workgdf_residential['borough'].map(boro_to_county)\n",
    "\n",
    "## Remove trailing zeros in the census tract column so we can format it to match the LODES data format\n",
    "\n",
    "def clean_census_tract_strings(gdf):\n",
    "    \n",
    "    def remove_trailing_dot_zero(s):\n",
    "        if isinstance(s, str) and s.endswith('.0'):\n",
    "            return s[:-2]  # Remove the last two characters\n",
    "        return s\n",
    "\n",
    "    gdf = gdf.dropna(subset='bct2020').reset_index()\n",
    "    gdf['bct2020']=gdf['bct2020'].astype(str)\n",
    "    gdf['bct2020']=gdf['bct2020'].str[1:]\n",
    "    gdf['census_tract'] = gdf['bct2020'].astype(str).apply(remove_trailing_dot_zero)\n",
    "    gdf['census_tract']=gdf['census_tract'].astype(int)\n",
    "    gdf['census_tract']=gdf['census_tract'].astype(str)\n",
    "    gdf['trct_formatted'] = gdf['census_tract'] + \" \" + \"(\" + gdf['County']+ \")\"\n",
    "    gdf['distance_to_ferry']=gdf['res_geometry'].distance(gdf['ferry_geometry'])/1600\n",
    "    gdf['distance_to_subway']=gdf['res_geometry'].distance(gdf['subway_geometry'])/1600\n",
    "\n",
    "### Finally, filter LODES data so that it only includes tracts near ferry landings\n",
    "\n",
    "residential_tracts = set(list(gdf_residential['trct_formatted']))\n",
    "work_tracts = set(list(gdf_work['trct_formatted']))\n",
    "\n",
    "lodes_data_ferry = lodes_data[lodes_data['trctname_home'].isin(residential_tracts)]\n",
    "lodes_data_ferry = lodes_data_ferry[lodes_data_ferry['trctname_work'].isin(work_tracts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7191b53c-2e51-43e5-ab59-66609af07e16",
   "metadata": {},
   "source": [
    "## 4. Determine distances between subway stops and between ferry landings\n",
    "\n",
    "Create matrices that (1) map each subway stop to every other subway stop in the system and (2) map each ferry landing to every other ferry landing in the system. Ideally, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b644a5-f236-4457-a76a-d12e1ff04f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Create subway-subway matrix from subway stations within the non-residential address dataset\n",
    "\n",
    "subway_matrix1 = gdf_residential_with_ferry[['subway_lat', 'subway_lon', 'stop_name_left','Line']].\\\n",
    "                drop_duplicates(subset='stop_name_left')\n",
    "subway_matrix2 = gdf_work_with_ferry[['subway_lat', 'subway_lon', 'stop_name_left','Line']].\\\n",
    "                drop_duplicates(subset='stop_name_left')\n",
    "\n",
    "subway_matrix = pd.concat([subway_matrix1,subway_matrix2])\n",
    "\n",
    "## Remove Staten Island Railway stations, since these do not connect to anywhere outside of the borough\n",
    "## Also, it is impossible to take the ferry within Staten Island\n",
    "\n",
    "subway_matrix_no_si = subway_matrix[subway_matrix['Line']!='S']\n",
    "subway_matrix_no_si_2 = subway_matrix_no_si.copy()\n",
    "\n",
    "cartesian_product = pd.DataFrame(itertools.product(subway_matrix_no_si.values.tolist(), \n",
    "                                                   subway_matrix_no_si_2.values.tolist()),columns=['Subway_Stops_1', \n",
    "                                                                                                   'Subway_Stops_2'])\n",
    "\n",
    "#Flatten the tuples into columns\n",
    "subway_matrix1 = cartesian_product_h['Subway_Stops_1'].apply(pd.Series)\n",
    "subway_matrix1.columns = [f\"Subway1_{col}\" for col in subway_matrix1.columns]\n",
    "\n",
    "subway_matrix2 = cartesian_product_h['Subway_Stops_2'].apply(pd.Series)\n",
    "subway_matrix2.columns = [f\"Subway2_{col}\" for col in subway_matrix2.columns]\n",
    "\n",
    "# Combine the dataframes with prefixed column names\n",
    "cartesian_product_h = pd.concat([subway_matrix1, subway_matrix2], axis=1)\n",
    "\n",
    "cartesian_product_h['Subway_1_Name_Line']=cartesian_product_h['Subway1_2']+'/'+cartesian_product_h['Subway1_3'].astype(str)\n",
    "cartesian_product_h['Subway_2_Name_Line']=cartesian_product_h['Subway2_2']+'/'+cartesian_product_h['Subway2_3'].astype(str)\n",
    "\n",
    "## Remove duplicates\n",
    "cartesian_product_h = cartesian_product_h[cartesian_product_h['Subway_1_Name_Line'] != cartesian_product_h['Subway_2_Name_Line']]\n",
    "\n",
    "## Create coordinates columns \n",
    "cartesian_product_h['start_coord'] = cartesian_product_h['Subway1_0'].astype(str) + \", \" + cartesian_product_h['Subway1_1'].astype(str)\n",
    "cartesian_product_h['end_coord'] = cartesian_product_h['Subway2_0'].astype(str) + \", \" + cartesian_product_h['Subway2_1'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258fc969-978c-4477-9cb5-cdf70159ba65",
   "metadata": {},
   "source": [
    "## 5. Call the Google Maps Directions API to determine the duration on the subway between all stops in the dataset\n",
    "\n",
    "Ideally, we would be able to make an API call for every single hypothetical address-to-address pair we choose. But this is expensive, and I do not have the money to pay for that many API calls. So instead, we have to settle for constructing the commute leg-by-leg. That way, we minimize the amount of API calls we have to make. The only API calls we have to make will determine the travel time between a) every subway station in the MTA and b) every ferry landing in the system. Later, we can just approximate the walking distances by assuming an average walking speed, and assuming people are walking square blocks (rather than as the crow flies -- unless they can walk through buildings!) to their destinations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c5ff8e-7e8d-472b-b452-177fa940017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import googlemaps\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "\n",
    "gmaps = googlemaps.Client(key=\"REDACTED")\n",
    "\n",
    "\n",
    "def travel_time(start_coord, end_coord):\n",
    "\n",
    "    tz = timezone('EST')\n",
    "\n",
    "    dep_time = datetime(2024, 9, 17, 8, 00, 00, tzinfo=tz)\n",
    "\n",
    "    directions_result = gmaps.directions(start_coord, end_coord, mode=\"transit\",\n",
    "                                     departure_time=dep_time, avoid='ferries')\n",
    "\n",
    "    duration = directions_result[0]['legs'][0]['duration']['value']/60\n",
    "\n",
    "    return duration\n",
    "\n",
    "cartesian_product_h['duration'] = cartesian_product_h.apply(lambda row: travel_time(row['start_coord'], \n",
    "                                                                                    row['end_coord']), axis=1)\n",
    "\n",
    "subway_durations = cartesian_product_h.copy()\n",
    "\n",
    "results = []\n",
    "\n",
    "gmaps = googlemaps.Client(key=\"REDACTED\")\n",
    "\n",
    "def travel_time(start_coord, end_coord):\n",
    "\n",
    "    tz = timezone('EST')\n",
    "\n",
    "    dep_time = datetime(2024, 9, 20, 9, 00, 00, tzinfo=tz)\n",
    "\n",
    "    directions_result = gmaps.directions(start_coord, end_coord, mode=\"transit\",\n",
    "                                     departure_time=dep_time)\n",
    "\n",
    "    results.append(directions_result)\n",
    "\n",
    "    duration = directions_result[0]['legs'][0]['duration']['value']/60\n",
    "\n",
    "    return duration\n",
    "\n",
    "all_ferry_routes['duration'] = all_ferry_routes.apply(lambda row: travel_time(row['start_coord'],row['end_coord']), axis=1)\n",
    "\n",
    "ferry_durations=all_ferry_routes.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79075da-9f43-4fc9-99d1-b645265848d9",
   "metadata": {},
   "source": [
    "## 6: Group our non-residential and residential dataframes by the tract they are in \n",
    "\n",
    "Create sub-dataframes, and then a dictionary of these sub-dataframes, that include only the addresses for a singular census tract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7e069c-a1cc-44f3-bd9e-a23d42d653c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = gdf_residential_with_ferry_nodups.groupby('trct_formatted')\n",
    "grouped_nonres = gdf_work_with_ferry_nodups.groupby('trct_formatted')\n",
    "\n",
    "# Create a dictionary to hold the DataFrames\n",
    "dataframes = {name: group.reset_index(drop=True) for name, group in grouped}\n",
    "dataframes_nonres = {name: group.reset_index(drop=True) for name, group in grouped_nonres}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcdea6e-aa89-4133-9e25-05125f5ecb10",
   "metadata": {},
   "source": [
    "## 7. Determine walking distances between ferry landings and subway stations for multimodal commutes\n",
    "\n",
    "In our data, each address has proximate subway stop and a proximate ferry landing. For multimodal commutes, though, commuters will have to walk from a subway stop to a ferry landing, or vice versa. We need to know the distance between these transit stops to accurately estimate walking time. We will create a key that allows us to match walking durations to walking routes in the data. We create a matrix mapping ferry landings to subway stops, and then using the Haversine formula, determine the walking distance. Finally, our key will be a dictionary matching the route taken to the distance of the walk. \n",
    "\n",
    "For an illustrative example, one key entry may be {\"Astoria to 30 Av\": 0.9}. So, if a particular multimodal commute in our data involves walking from the Astoria ferry landing to the 30 Av subway stop, then we know it will be 0.9 miles, and probably take about 15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aba04c-2111-460e-b528-1b7709dca032",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in durations between subway stops and between ferry landings\n",
    "\n",
    "def make_durations_keys(mode):\n",
    "    key = mode[['origin_stop','destination_stop','duration']]\n",
    "    key['route_index'] = key['origin_stop']+' to ' +key['destination_stop']\n",
    "    key_dict = key[['route_index','duration']].set_index('route_index')['duration'].to_dict()\n",
    "    return dict\n",
    "\n",
    "ferry_durations_key = make_durations_keys(ferry_durations)\n",
    "subway_durations_key = make_durations_keys(subway_durations)\n",
    "\n",
    "ferry_stops=ferry_stops.rename(columns={'stop_lon':'ferry_lon', 'stop_lat':'ferry_lat'})\n",
    "subway_stops=subway_stops.rename(columns={'stop_lon':'subway_lon', 'stop_lat':'subway_lat'})\n",
    "\n",
    "import itertools\n",
    "cartesian_product = pd.DataFrame(itertools.product(subway_stops.values.tolist(), \n",
    "                                                   ferry_stops.values.tolist()),columns=['Subway Stops',\n",
    "                                                                                         'Ferry Stops'])\n",
    "\n",
    "#Flatten the tuples into columns\n",
    "subway_df = cartesian_product['Subway Stops'].apply(pd.Series)\n",
    "subway_df.columns = [f\"Subway_{col}\" for col in subway_df.columns]\n",
    "\n",
    "ferry_df = cartesian_product['Ferry Stops'].apply(pd.Series)\n",
    "ferry_df.columns = [f\"Ferry_{col}\" for col in ferry_df.columns]\n",
    "\n",
    "# Combine the dataframes with prefixed column names\n",
    "cartesian_product = pd.concat([subway_df, ferry_df], axis=1)\n",
    "\n",
    "cartesian_product.rename(columns={'Subway_2': 'Subway Stop Name', 'Subway_3': 'Subway_Stop_Latitude', \n",
    "                                  'Subway_4': 'Subway_Stop_Longitude', 'Ferry_3': 'Ferry Stop Name',\n",
    "                                  'Ferry_18': 'Ferry_Stop_Latitude', 'Ferry_17': 'Ferry_Stop_Longitude',\n",
    "                                 'Subway_7':'stop_name_line'}, \n",
    "                         inplace=True)\n",
    "\n",
    "subway_ferry_matrix = cartesian_product[['Subway Stop Name',\n",
    "'Subway_Stop_Latitude', \n",
    "'Subway_Stop_Longitude',\n",
    "'Ferry Stop Name',\n",
    "'Ferry_Stop_Latitude',\n",
    "'Ferry_Stop_Longitude',\n",
    "'stop_name_line']]\n",
    "\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2, to_radians=True, earth_radius=3963):\n",
    "    \n",
    "    if to_radians:\n",
    "        lat1, lon1, lat2, lon2 = np.radians([lat1, lon1, lat2, lon2])\n",
    "\n",
    "    a = np.sin((lat2-lat1)/2.0)**2 + \\\n",
    "        np.cos(lat1) * np.cos(lat2) * np.sin((lon2-lon1)/2.0)**2\n",
    "\n",
    "    return earth_radius * 2 * np.arcsin(np.sqrt(a))\n",
    "\n",
    "subway_ferry_matrix['Distance between Ferry and Subway Stop'] = subway_ferry_matrix.apply(lambda row: \\\n",
    "                                                                                          haversine(row['Subway_Stop_Latitude'],\n",
    "                                                                                            row['Subway_Stop_Longitude'],\n",
    "                                                                                            row['Ferry_Stop_Latitude'],\n",
    "                                                                                            row['Ferry_Stop_Longitude']), axis=1,\n",
    "                                                                                            result_type = 'expand')\n",
    "\n",
    "subway_ferry_distances = subway_ferry_matrix.pivot_table(index='Ferry Stop Name',\n",
    "                          values = 'Distance between Ferry and Subway Stop',\n",
    "                          aggfunc = np.min).reset_index().merge(subway_ferry_matrix, /\n",
    "                                                                \n",
    "                                                                on='Distance between Ferry and Subway Stop'). \\\n",
    "                                                                drop_duplicates(subset=['Ferry Stop Name_x',\n",
    "                                                                                        'Subway Stop Name'])\n",
    "\n",
    "subway_ferry_distances_index = subway_ferry_distances[['Subway Stop Name', 'Ferry Stop Name_x','Distance between Ferry and Subway Stop']]\n",
    "\n",
    "\n",
    "subway_ferry_distances_index['ferry_subway_index_fts'] = subway_ferry_distances_index['Ferry Stop Name_x']+ ' to ' + \\ \n",
    "                                                        subway_ferry_distances_index['Subway Stop Name']\n",
    "subway_ferry_distances_index['ferry_subway_index_stf'] = subway_ferry_distances_index['Subway Stop Name']+ ' to ' + \\ \n",
    "                                                        subway_ferry_distances_index['Ferry Stop Name_x']\n",
    "\n",
    "subway_ferry_distances_index_fts_key =subway_ferry_distances_index[['ferry_subway_index_fts',\n",
    "                                                                    'Distance between Ferry and Subway Stop']].\\\n",
    "                                                set_index('ferry_subway_index_fts')['Distance between Ferry and Subway Stop'].to_dict()\n",
    "\n",
    "subway_ferry_distances_index_stf_key =subway_ferry_distances_index[['ferry_subway_index_stf',\n",
    "                                                                    'Distance between Ferry and Subway Stop']].\\\n",
    "                                                set_index('ferry_subway_index_stf')['Distance between Ferry and Subway Stop'].to_dict()\n",
    "\n",
    "closest_subway_to_ferry =subway_ferry_distances_index[['Subway Stop Name', 'Ferry Stop Name_x',\n",
    "                                                                    'Distance between Ferry and Subway Stop']].\\\n",
    "                                                set_index('Ferry Stop Name_x')['Subway Stop Name'].to_dict()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e267c079-0a7b-4d67-ac2e-fb98f083c831",
   "metadata": {},
   "source": [
    "## 8. Finally, create random hypothetical commutes and determine their travel time\n",
    "\n",
    "This is the final and most critical part of the script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf82036-a74b-44ac-b1a2-7eb4babeda85",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for each row, randomly select 50 origins and 50 destinations\n",
    "\n",
    "ferry_travelers = []\n",
    "\n",
    "for i in range(1,50):\n",
    "\n",
    "    ## Filter out observations not accessible by ferry or subway\n",
    "    \n",
    "    lodes_data_resfilter = lodes_data_ferry[lodes_data_ferry['trctname_home'].isin(dataframes.keys())]\n",
    "    lodes_data_res_work_filter = lodes_data_resfilter[lodes_data_resfilter['trctname_work'].isin(dataframes_nonres.keys())]\n",
    "\n",
    "    ## Initialize dataframe with out random pairs\n",
    "    \n",
    "    random_o_d_pairs = {}\n",
    "    \n",
    "    lodes_data_res_work_filter_list = lodes_data_ferry[['trctname_home', 'trctname_work']].values.tolist()\n",
    "\n",
    "    ## Create a set of valid origin-destination pairs\n",
    "    \n",
    "    valid_pairs_set = set(map(tuple, lodes_data_res_work_filter_list))\n",
    "\n",
    "    print('Dataset Filtered')\n",
    "\n",
    "    ## Define our function that chooses random home-work pairs\n",
    "    \n",
    "    def select_random_o_d(o_d_list):\n",
    "    \n",
    "        ## Loop thru each origin-destination pair\n",
    "        \n",
    "        for i in range(len(lodes_data_res_work_filter_list)):\n",
    "\n",
    "            ## Create a pair in the format \"[Origin Tract], [Destination Tract]\"\n",
    "        \n",
    "            pair = str(lodes_data_res_work_filter_list[i][0]) + \", \" + str(lodes_data_res_work_filter_list[i][1])\n",
    "            \n",
    "            origins = select_random_origins(lodes_data_res_work_filter_list[i][0]).add_prefix('home')\n",
    "            destinations = select_random_destinations(lodes_data_res_work_filter_list[i][1]).add_prefix('work')\n",
    "\n",
    "            ## \"Smush\" together the randomly selected origin and destinatioj\n",
    "            \n",
    "            o_d_pair = pd.concat([origins, destinations], axis=1).dropna(subset='worktrct_formatted').dropna(subset='hometrct_formatted')\n",
    "            \n",
    "            random_o_d_pairs[pair] = o_d_pair\n",
    "\n",
    "    ## Function that randomly (but representatively) selects origins\n",
    "    \n",
    "    def select_random_origins(origin):\n",
    "    \n",
    "        df_origin = dataframes[origin]\n",
    "        \n",
    "        if df_origin.empty:\n",
    "            return None  # Handle empty DataFrame case\n",
    "        weights = df_origin['unitsres'] / df_origin['unitsres'].sum()  # Normalize weights\n",
    "        return df_origin.sample(n=min(50, len(df_origin)), replace=True, weights=weights).reset_index()\n",
    "\n",
    "    ## Function that randomly (but representatively) selects destinations\n",
    "    \n",
    "    def select_random_destinations(destination):\n",
    "    \n",
    "        df_destination = dataframes_nonres[destination]\n",
    "        \n",
    "        if df_destination.empty:\n",
    "            return None  # Handle empty DataFrame case\n",
    "        weights = df_destination['lotarea'] / df_destination['lotarea'].sum()  # Normalize weights\n",
    "        return df_destination.sample(n=min(50, len(df_destination)), replace=True, weights=weights).reset_index()\n",
    "\n",
    "    ## Execute function that smushes together our randomized origin-destination dataframes\n",
    "        \n",
    "    select_random_o_d(lodes_data_res_work_filter_list)\n",
    "\n",
    "    ## Turn our dictionary into a dataframe\n",
    "    \n",
    "    combined_df = pd.concat(random_o_d_pairs.values(), ignore_index=True)\n",
    "\n",
    "    print('combined dataframe generated')\n",
    "\n",
    "    \n",
    "    \n",
    "    combined_df['od_index'] = combined_df['hometrct_formatted']+'/'+combined_df['worktrct_formatted']\n",
    "\n",
    "    ## Determine total jobs of all types for each origin-destination pair\n",
    "    \n",
    "    lodes_data_ferry['total_jobs'] = lodes_data_ferry['SA01']+lodes_data_ferry['SA02']+lodes_data_ferry['SA03']\n",
    "    lodes_data_ferry['od_index']=lodes_data_ferry['trctname_home']+'/'+lodes_data_ferry['trctname_work']\n",
    "    lodes_data_ferry_dict = lodes_data_ferry[['od_index','total_jobs']].set_index('od_index').to_dict()['total_jobs']\n",
    "    \n",
    "    combined_df = combined_df[combined_df['od_index'].isin(lodes_data_ferry_dict.keys())]\n",
    "\n",
    "    ## Identify closest subway to home and work ferry landings. This is critical for calculating walking distances\n",
    "    combined_df['closest_subway_to_home_ferry'] = combined_df['homestop_name_right'].map(closest_subway_to_ferry)\n",
    "    combined_df['closest_subway_to_work_ferry'] = combined_df['workstop_name_right'].map(closest_subway_to_ferry)\n",
    "    \n",
    "    ## Now, create indices that identify the origin and destination transit stops. We will map these indices to our key we created above.\n",
    "\n",
    "    ##### Create indices identifying the transit between a) origin transit station/landing \n",
    "    ##### and b) origin transit station/landing\n",
    "    combined_df['subway_to_subway_index'] = combined_df['homestop_name_left'] + ' to '  +combined_df['workstop_name_left']\n",
    "    combined_df['ferry_to_ferry_index'] = combined_df['homestop_name_right'] + ' to ' + combined_df['workstop_name_right']\n",
    "    \n",
    "    ##### Create indices identifying the transit between a) origin subway station \n",
    "    ##### and b) subway you arrive at before getting on the ferry\n",
    "    combined_df['multimodal_two_home_subways_index'] = combined_df['homestop_name_left'] + ' to ' + \\ \n",
    "                                                        combined_df['closest_subway_to_home_ferry']\n",
    "    \n",
    "    ##### Create indices identifying the transit between a) subway station you get on after getting OFF the ferry \n",
    "    ##### and b) subway you arrive at before walking to work\n",
    "    combined_df['multimodal_two_work_subways_index'] = combined_df['closest_subway_to_work_ferry'] + ' to ' + \\ \n",
    "                                                        combined_df['workstop_name_left']\n",
    "    \n",
    "    ##### Create indices identifying the transit between a) subway station nearest to your home and\n",
    "    ##### b) the subway station you arrive at before getting on ferry\n",
    "    combined_df['home_subway_to_home_ferry_index'] = combined_df['homestop_name_right'] + ' to ' + \\ \n",
    "                                                    combined_df['closest_subway_to_home_ferry'] \n",
    "\n",
    "    ##### Create indices identifying the transit between a) subway station you walk to after getting OFF the ferry and \n",
    "    ##### b) the subway station near your workplace \n",
    "\n",
    "    combined_df['work_ferry_to_work_subway_index'] = combined_df['closest_subway_to_work_ferry'] ' to ' + \\\n",
    "    combined_df['workstop_name_right'] \n",
    "\n",
    "    # FINALLY: calculate transit times\n",
    "    \n",
    "    ## Calculate pure, single-mode ferry trip\n",
    "    \n",
    "    combined_df['ferry_to_ferry_duration'] = combined_df['ferry_to_ferry_index'].map(ferry_durations_key_dict)\n",
    "    combined_df['walk_from_home_to_ferry_duration'] = combined_df['homedistance_to_ferry']*16\n",
    "    combined_df['walk_from_ferry_to_work_duration'] = combined_df['workdistance_to_ferry']*16\n",
    "    combined_df['pure_ferry_duration'] = combined_df['ferry_to_ferry_duration']+ \\ \n",
    "    combined_df['walk_from_home_to_ferry_duration']+combined_df['walk_from_ferry_to_work_duration']\n",
    "   \n",
    "    ## Calculate pure, single-mode subway trip\n",
    "    \n",
    "    combined_df['subway_to_subway_duration']=combined_df['subway_to_subway_index'].map(subway_durations_key_dict)\n",
    "    combined_df['walk_from_home_to_subway_duration']=combined_df['homedistance_to_subway']*16\n",
    "    combined_df['walk_from_subway_to_work_duration']=combined_df['workdistance_to_subway']*16\n",
    "    \n",
    "    ## Calculate multimodal trips\n",
    "    \n",
    "    ##### Multimodal trip 1: Ride subway to the ferry, then walk to work\n",
    "    ########## EXAMPLE: Take the subway from Greenpoint to the Greenpoint ferry landing, take ferry to E 34th St, then walk to work\n",
    "    \n",
    "    ## Walk to subway (already calculated, we know distance to closest subway stop)\n",
    "    combined_df['multimodal_subway_to_subway_duration_home'] = \\\n",
    "\n",
    "\n",
    "    ## Walk to ferry\n",
    "    combined_df['walk_from_second_home_subway_to_home_ferry_duration'] = \\\n",
    "    combined_df['home_subway_to_home_ferry_index'].map(subway_ferry_distances_index_stf_key)*16\n",
    "\n",
    "    ## take ferry (already calculated, we know duration between ferry landings)\n",
    "    ## walk from ferry to work (already calculated, we know distance from ferry landing to work)\n",
    "\n",
    "    ### Add the route together\n",
    "    combined_df['subway_to_ferry_to_work_duration'] =combined_df['walk_from_home_to_subway_duration']+ \\\n",
    "    combined_df['multimodal_subway_to_subway_duration_home']+combined_df['walk_from_second_home_subway_to_home_ferry_duration']+\\\n",
    "    combined_df['ferry_to_ferry_duration']+combined_df['walk_from_ferry_to_work_duration']\n",
    "    \n",
    "    ##### Multimodal trip 2: Ride ferry to the subway, then ride to work. \n",
    "    ########## EXAMPLE: Take the ferry from Rockaway to Wall St. Pier 11, then take the train uptown.\n",
    "    \n",
    "    ## Walk to ferry landing (already calculated)\n",
    "    ## Take ferry (already calculated)\n",
    "    ## Walk from the destination ferry landing to the subway\n",
    "    \n",
    "    combined_df['walk_from_work_ferry_to_work_subway_duration'] = \\\n",
    "    combined_df['work_ferry_to_work_subway_index'].map(subway_ferry_distances_index_fts_key)*16\n",
    "    \n",
    "    ## Take the subway to the station closest to work\n",
    "    combined_df['multimodal_subway_to_subway_duration_work_side'] = \\\n",
    "    combined_df['multimodal_two_work_subways_index'].map(subway_durations_key_dict)\n",
    "\n",
    "    ## Walk from subway to work (already calculated)\n",
    "    \n",
    "    ### Add the route together\n",
    "    combined_df['ferry_to_subway_to_work_duration'] = combined_df['walk_from_home_to_ferry_duration']+ \\ \n",
    "    combined_df['ferry_to_ferry_duration']+ combined_df['walk_from_work_ferry_to_work_subway_duration']+ \\\n",
    "    combined_df['multimodal_subway_to_subway_duration_work_side']+combined_df['walk_from_subway_to_work_duration']\n",
    "    \n",
    "    ##### Multimodal trip 3: Ride subway to the ferry, take the ferry, hop on the subway again to work\n",
    "    ########## EXAMPLE: Take the subway to the Bay Ridge landing, take the ferry to Wall St./Pier 11, take the subway to work\n",
    "    \n",
    "    ## Walk to subway (already calculated)\n",
    "    ## Take subway to the ferry (already calculated)\n",
    "    ## Take the ferry (already calcuated)\n",
    "    ## Walk from the destination ferry to the subway (already calcuated)\n",
    "    ## Take the subway to your final work destination (already calcuated)\n",
    "    ## Walk from work subway to work (already calculated)\n",
    "\n",
    "    ### Add the route together\n",
    "    combined_df['subway_to_ferry_to_subway_to_work_duration'] =combined_df['walk_from_home_to_subway_duration']+ \\\n",
    "    combined_df['multimodal_subway_to_subway_duration_home']+ \\ \n",
    "    combined_df['walk_from_second_home_subway_to_home_ferry_duration']+ \\ \n",
    "    combined_df['ferry_to_ferry_duration']+combined_df['walk_from_work_ferry_to_work_subway_duration']+ \\\n",
    "    combined_df['multimodal_subway_to_subway_duration_work_side']+combined_df['walk_from_subway_to_work_duration']\n",
    "\n",
    "    ### Determine, for each commute, if any ferry route or multimodal route is faster than a pure subway route\n",
    "    combined_df['pure_ferry_faster_than_pure_subway?'] = combined_df['pure_ferry_duration']<combined_df['pure_subway_duration']\n",
    "    combined_df['multimodal_ferry_to_subway_faster_than_pure_subway?'] = \\\n",
    "    combined_df['ferry_to_subway_to_work_duration']<combined_df['pure_subway_duration']\n",
    "    combined_df['multimodal_subway_to_ferry_faster_than_pure_subway?'] = \\\n",
    "    combined_df['subway_to_ferry_to_work_duration']<combined_df['pure_subway_duration']\n",
    "    combined_df['multimodal_subway_to_ferry_to_subway_faster_than_pure_subway?'] = \\ \n",
    "    combined_df['subway_to_ferry_to_subway_to_work_duration']<combined_df['pure_subway_duration']\n",
    "\n",
    "    ## set columns containing a commute duration\n",
    "    duration_cols = ['pure_subway_duration',\n",
    "    'pure_ferry_duration',\n",
    "    'ferry_to_subway_to_work_duration',\n",
    "    'subway_to_ferry_to_work_duration',\n",
    "    'subway_to_ferry_to_subway_to_work_duration']\n",
    "\n",
    "    ## set columns representing a commute duration ON THE FERRY\n",
    "    ferry_cols =  ['pure_ferry_duration',\n",
    "    'ferry_to_subway_to_work_duration',\n",
    "    'subway_to_ferry_to_work_duration',\n",
    "    'subway_to_ferry_to_subway_to_work_duration']\n",
    "\n",
    "    ## Find the minimum value of all duration columns\n",
    "    combined_df['min_value'] = combined_df[duration_cols].min(axis=1)\n",
    "    combined_df['min_column'] = combined_df[duration_cols].idxmin(axis=1)\n",
    "    combined_df['min_column'] = combined_df['min_column'].fillna('NaN')\n",
    "\n",
    "    ## Find the minimum vakue of ferry durations\n",
    "    combined_df['min_ferry_val'] = combined_df[ferry_cols].min(axis=1)\n",
    "    combined_df['min_ferry_column'] = combined_df[ferry_cols].idxmin(axis=1)\n",
    "    combined_df['min_ferry_column'] = combined_df['min_ferry_column'].fillna('NaN')\n",
    "    \n",
    "    ## Create a column representing 1 if a ferry route is faster than the subway and 0 if not\n",
    "    combined_df['ferry_faster_than_subway'] = combined_df['min_column'].apply(lambda col: 1 if 'ferry' in col else 0)\n",
    "    combined_df['Count']=1\n",
    "\n",
    "    ## Determine, for each commute combination, the amount of commuters for whom the ferry is faster\n",
    "    \n",
    "    ferry_faster_piv = combined_df.pivot_table(index = 'od_index',\n",
    "                                                    values = 'ferry_faster_than_subway',\n",
    "                                                             'Count'],\n",
    "                                                    aggfunc='sum').reset_index()\n",
    "\n",
    "    ## Determine the proportion of commuters for each unique commute for whom the ferry is faster\n",
    "    ferry_faster_piv['proportion_where_ferry_is_faster']=ferry_faster_piv['ferry_faster_than_subway']/ferry_faster_piv['Count']\n",
    "    \n",
    "    ## Determine, for each unique commute, how many commuters there actually are\n",
    "    lodes_data_ferry_dict = lodes_data_ferry[['od_index','total_jobs']].set_index('od_index').to_dict()['total_jobs']\n",
    "    ferry_faster_piv['jobs']=ferry_faster_piv['od_index'].map(lodes_data_ferry_dict)\n",
    "\n",
    "    ## Multiply the total commuters by the proportion of commuters for whom the ferry is fasted\n",
    "    ## this gets us the GROSS TOTAL COMMUTERS FOR WHOM THE FERRY IS FASTED\n",
    "    ferry_faster_piv['ferry_speed_commuters'] = ferry_faster_piv['proportion_where_ferry_is_faster']*ferry_faster_piv['jobs']\n",
    "    total_ferry_speed_riders = ferry_faster_piv['ferry_speed_commuters'].sum()\n",
    "\n",
    "    ## Add this to our running list of randomized values. Later, we will plot a histogram for this.\n",
    "    ferry_travelers.append(total_ferry_speed_riders)\n",
    "    \n",
    "    print(ferry_travelers[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
